---
chapter: 4
knit: "bookdown::render_book"
---

# Modelling {ch: Modelling}
Let $\textbf{v}_i = (v_{i1}, v_{i2}, ..., v_{iD})$ denote the vector holding the percentage of votes for parties in electorate $i$, for each of the D parties, and $\textbf{x}_i = (x_{i1}, x_{i2},...,x_{ik})$ is a vector of $k$  socio-demographic covariates that characterise the electorate. This study is focused on modelling $\textbf{v}_i = f(\textbf{x}_i) + \textbf{u}_i$, where $\textbf{u}_i$ is the error term.

A reminder that $\textbf{v}_i = (v_{i1}, v_{i2}, ..., v_{iD})$ where $\sum_{j=1}^D\textbf{v}_{ij} = 1$

## Logratio analysis
Logratio analysis (Aitchison 1986) uses the transformation of the response $\textbf{v}_i$ to $\textbf{w}_i$, where $\textbf{w}_i \in \mathbb{R}^D$ (or $\mathbb{R}^{D-1}$), and $\dim(\textbf{w}_i) \text{ is } D\times1 \text{ or } (D-1) \times 1$, depending on the transformation method. To obtain $\textbf{w} =  (w_{i1}, w_{i2}, ..., w_{iD})$ or $\textbf{w} =  (w_{i1}, w_{i2}, ..., w_{i(D-1)})$ there are three available mappings: additive, centred and isometric.

Since the transformed $\textbf{w}_i \in \mathbb{R}^D$, the joint distribution can be modelled as multivariate normal, $\textbf{w}_i \sim{N({\mu_i}, {\bf \Sigma}})$, where ${\bf\mu}_i = f({\bf x}_i)$. Parametric specifications of $f({\bf x}_i)$ are used, and estimates conducted using maximum likelihood.


#### Additive Logratio
Maps to $\mathbb{R}^{D} \text{ for } {\bf v}_i \to {\bf w}_i$

$$\text{alr}(v_{ij}) = w_{ij} = \text{ln}(v_{ij}/v_{iD}), \space \forall \space j \in \{1,...,D\}$$

$$\text{alr}({\bf v}_i) = (\frac{\text{ln}(v_{i1})}{\text{ln}(v_{iD})}, ..., \frac{\text{ln}(v_{i(D-1)})}{\text{ln}(v_{iD})}, 1) = \text{ln}({\bf v}_i)\space \begin{bmatrix}
    1 & 0 & ... & 0 \\
    0 & 1 & ... & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & ... & 1 \\
    -1 & -1 & ... & -1
\end{bmatrix}$$

Transform back to $\textbf{v}_i$ using: $\textbf{v}_i = \exp(\textbf{w}_i) \cdot v_{iD}$


#### Centred Logratio
Maps to $\mathbb{R}^{D} \text{ for } {\bf v}_i \to {\bf w}_i$. Let $g({\bf v_i}) = \sqrt[D]{\prod_{j=1}^D v_{ij}}$.

$$\text{clr}(v_{ij}) = w_{ij} = \text{ln}(\frac{v_{ij}}{g({\bf v_i})}), \forall \space j \in \{1,...,D\}$$

$$\text{clr}({\bf v}_i) = \Big(\text{ln}(\frac{v_{i1}}{g({\bf v_i})}),...,\text{ln}(\frac{v_{iD}}{g({\bf v_i})}))\Big) \\ = \frac{\text{ln}({\bf x}_i)}{D} \cdot \begin{bmatrix}
    D-1 & -1 & ... & -1 \\
    -1 & D-1 & ... & -1 \\
    \vdots & \vdots & \ddots & \vdots \\
    -1 & -1 & ... & D-1
\end{bmatrix}$$

Transform back to $\textbf{v}_i$ using: $v_{ij} = \frac{\exp(w_{ij})}{\sum_{j=1}^D \exp(w_{ij})}$


#### Isometric Logratio
Maps to $\mathbb{R}^{D-1} \text{ for } {\bf v}_i \to {\bf w}_i$.

$$\text{ilr}_M({\bf v}_i) = clr({\bf v}_i)\cdot{\bf M} = \text{ln}({\bf v}_i) \cdot {\bf M}$$

Where $\bf M$ is a matrix of $D$ rows and $D-1$ columns such that ${\bf M} \cdot {\bf M}^t = {\bf I}_{D-1}$. ${\bf I}_{D-1}$ is the identity matrix of $D-1$ elements.

Transform back to $\bf{v}_i$ as: ${\bf v}_i = \exp({\bf w}_i \space \cdot \space {\bf M^{-1}})$



## Dirichlet covariate model
No transformation of the data is necessary, the vector $\textbf{v}_i$ remains as is - a vector holding the percentage of votes for parties in each electorate $i$ in $1,...,D$.

### Dirichlet Distribution
Note: that subscript $i$ has been dropped for the following section for simplicity.

Let $\textbf{v} = (v_{1}, v_{2}, ..., v_{D})$ be a $1 \times D$ positive vector having Dirichlet distribution with positive parameters ${\bf \lambda} = (\lambda_1, ..., \lambda_D)$ with density function:
$$f({\bf v}) = \Big(\Gamma(\lambda)/\prod_{j=1}^D \Gamma(\lambda_j) \Big) \prod_{j=1}^D v_j^{\lambda_j - 1}$$
where $\sum_{j=1}^D x_j = 1$ and $\lambda = \sum_{j=1}^D \lambda_j$.
Mean and variance are given by:
$$E(v_j)=\frac{\lambda_j}{\lambda}\text{ and }Var(v_j)=\frac{\lambda_j(\lambda-\lambda_j)}{(1+\lambda)\lambda^2}$$

### Covariate extension
The Dirichlet covariate model expands on this by setting $\lambda_j = h_j({\bf x})$, where $\bf x$ is a vector of covariates, and $h({\bf x}) = \sum_{j=1}^D h_j({\bf x})$. 
For example, ${\bf x} = (1,AusCitizen, EnglishOnly,  MedianPersonalIncome, Catholic)$.

The density function of this conditional distribution is:
$$f({\bf v|x}) = \Big(\Gamma(h({\bf x}))/\prod_{j=1}^D \Gamma(h_j({\bf x})) \Big) \prod_{j=1}^D v_j^{h_j({\bf x}) - 1}$$
with the conditional mean and variance for component $v_i$:
$$E(v_j|{\bf x}) = \frac{h_j({\bf x})}{h({\bf x})}$$
$$Var(v_j|{\bf x}) = \frac{\frac{h_j({\bf x})} {h({\bf x})}(h({\bf x})-\frac{h_j({\bf x})}{h({\bf x})})} {(1 + h({\bf x}))(h({\bf x}))^2}$$
and covariance
$$Cov(v_j,v_k|{\bf x}) = \frac{-h_j({\bf x})h_k({\bf x})} {h({\bf x})^2(h({\bf x})+1)}$$

This study uses parametric forms of $h({\bf x})$, so that inference can be conducted. The functinal forms to be estimated include (but are not limited to):

- Linear: $h_j({\bf x}) = {\bf x}'{\bf \beta}_j$ 

- Exponential: $h_j({\bf x}) = \exp({\bf x'\beta}_j)$

Where ${\bf \beta}_j = (\beta_{0j},\beta_{1j},...,\beta_{Lj})$, and ${\bf x} = (1, x_1, ..., x_L)$, meaning $L$ covariates are used. 

Parameters ${\bf \beta}_j$ are estimated using maximum likelihood (Campbell and Moismann, 1987; Hijazi, 2003), and bringing back the subscript $i$ for an electorate yields the estimates:

$$\hat{f}({\bf {v_i}|x_i}) = \Big(\Gamma(\hat{h}({\bf x}_i))/\prod_{j=1}^D \Gamma(\hat{h}_j({\bf x}_i)) \Big) \prod_{j=1}^D v_{ij}^{\hat{h}_j({\bf x}_i) - 1}$$
$$\hat{E}(v_{ij}|{\bf x}_i) = \frac{\hat{h}_j({\bf x}_i)}{\hat{h}({\bf x}_i)}$$
$$\hat{Var}(v_{ij}|{\bf x}_i) = \frac{\frac{\hat{h}_j({\bf x}_i)} {\hat{h}({\bf x}_i)}(\hat{h}({\bf x}_i)-\frac{\hat{h}_j({\bf x}_i)}{\hat{h}({\bf x}_i)})} {(1 + \hat{h}({\bf x}_i))(\hat{h}({\bf x}_i))^2}$$ 
$$\hat{Cov}(v_{ij},v_{ik}|{\bf x}_i) = \frac{-\hat{h_j}({\bf x}_i)\hat{h_k}({\bf x}_i)} {\hat{h}({\bf x}_i)^2(\hat{h}({\bf x}_i)+1)}$$

### Residuals
The marginals of the Dirichlet distribution are single Beta distributions (Hijazi, 2006), with parameters $\lambda_j$ and $\lambda - \lambda_j$, so $p_{ij} = F(v_{ij})$ is the (Beta) cumulative distribution function. Pseudo-residual is defined as $r_{ij} = \Phi^{-1}(p_{ij})$, where $\Phi^{-1}$ is the inverse cumulative distribution function of the standard normal. The pseudo-residuals $r_{ij}$ follow a standard normal distribution, if the Dirichlet distribution is the correct model. .



# Model Assessment and Diagnostics
Common tests for high leverage, goodness of fit and model selection are conducted for each model. The measures for high leverage include Cook's distance and Likelihood distance (Cook and Weisberg, 1982). Goodness of fit tests are Pearson's Chi-Square and Aitchison's ${\text R}^2$ measure of total variability (1986). Comparative assessment criteria include Aikaike Information Criteria (AIC) and the Likelihood-ratio test.

--- (Determine decision making / model selection strategy) ---

## High leverage
Cook's distance measures whether a modification of the data (perturbation) affects key characteristics of a model, which in this research is done by analysing the influence of each observation (electorate) on the parameter estimates.

Cook's distance is given by:
$$ cook $$
The higher a value of $D_i$ the more observation $i$ affects the parameter estimates. Cook and Weisberg (1982) suggest $D_i > 1$ as a cutoff for spotting influential points.

Likelihood distance is an adaptation of Cook's distance, which considers differences in likelihood, rather than prediction.

Likelihood distance is given by:
$$ likelihood dist $$

Comparisons are made between Cook's and Likelihood distance to check consistency of results.

## Goodness of fit
Pearson's Chi-Square statistic can be used to test whether the data has come from the modelled distiribution.
The chi-square statistic is given by:
$$ chi sq $$
and is asymptotically distributed with $\chi^2(D-1)$ (Boyles 1997).
Rejection of the (null) hypothesis that the data is from the modelled distribution at the 5% significance level is then:
$$ chi sq > \chi^2_{0.05}(D-1) $$

Aitchison's ${\text R}^2$ measure of total variability (1986) is based on the variation in logratio transformed data. This does not require Logratio analysis, and is applied to Dirichlet and Logratio models. Total variability is a relative measure of fitted variability against the variation in actual compositions.

$$ hijazi tot var $$

## Assessment criteria
Likelihood ratio test for nested models
AIC for comparison across different functional forms


