# Modelling {#ch:Modelling}

** To be inserted into chapter 4, as part 2 **

## Variable importance

We begin this chapter by making one thing absolutely clear. Full reality cannot be included in a model [@BurnhamAnderson2002]. Rather, we seek to estimate a good model to yield an estimate of the more prominent relationships that exist between socio-demographics and electorate voting behaviour, based on the empirical data in hand. 

Even after reducing the dimension of our data set, we still have 30 possible predictors to choose from, and only 150 observations. To estimate a *good* model, we use variable selection to further reduce our data to around 12 variables, which capture the five *most important* variables in determining $TPP$ in each election. Our approach is based off a technique common in ecological studies, using Akaike weights to measure relative variable importance [@BurnhamAnderson2002].

We construct an exhaustive set of potential models by first identifying Incomes, Unemployment and Education as three socio-demographic indicators that we are particularly interested in understanding. Our rationale is that Incomes may be relevant due to differences in party policies on personal (and business) taxation, the unemployment rate is a key indicator of economic conditions in an electorate, and one might expect higher education levels to have a particular party bias. In addition to these three, we include four other covariates in each model, and include every possible unique combination of the remaining 27 variables, resulting in a model set of 17550 models for each election - from which we draw conclusions about variable importance.


### A little bit of likelihood theory

This approach is fundamentally driven by Akaike's information criterion (AIC) [@Akaike73], which uses Kullback-Leibler (K-L) information as a basis for model selection [@BurnhamAnderson2002]. K-L information, $I$, for a true model $f$ and approximating model $g$ is given by:

$$I(f,g) = \int f(x) \log \Big( \frac {f(x)} {g(x|\theta)} \Big) dx$$ 

The K-L information can be interpreted as the information lost when $g$ is used to approximate $f$. Minimizing K-L distance is our goal in determining best fit, which is what we do by choosing a model (from a set) with minimum AIC.

By comparing the AIC of each model in the set with the minimum (optimal) AIC, we get a measure of relative information lost, and hence performance. Let $\Delta_m = AIC_m - AIC_{min}$, which is the difference in AIC between model $m$ and the minimum AIC in the model set. Akaike weights $w_m$ for each model $m$ are then calculated:

$$w_m = \frac {\exp(-\frac{1}{2}\Delta_m)} {\sum_{r=1} ^R \exp(-\frac{1}{2}\Delta_r)}$$

The Akaike weight represents the posterior probability that model $m$ is the best model in the set, without any beliefs a priori. The $w_m$ sum to one.

For each variable, we compute the sum of Akaike weights over models that include that variable, and use these as a measure of variable importance [@BurnhamAnderson2002]. Let $I$ denote the indicator function.

$$s_j = \sum_{j=1}^{J} \sum_{m=1}^{M} w_m \cdot I(j \text{ used in model } m)$$

We select the four variables with largest $s_j$ (excluding the three fixed variables) across all $j \in J$ for each election, and use the super-set of these variables as our chosen predictors to be used across *all* elections. The top four variables for each election are shown in figure \@ref(fig:top4varimp).

** Include table of top weights in appendix **

```{r top5varimp}
# table of top 5 most important variables each year
```

The resultant super-set includes: Incomes, Educ, Unemployed, Born_SE_Europe, ManagerAdminClericalSales, OneParent_House, LFParticipation, MedianAge, Extractive, RentLoan and SocialServ. 
