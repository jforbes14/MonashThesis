---
title: "Notes"
output: html_notebook
---




## Exponential Smoothing {#sec:expsmooth}

Exponential smoothing was originally developed in the late 1950s [@Brown59;@Brown63;@Holt57;@Winters60]. Because of their computational simplicity and interpretability, they became widely used in practice.

Empirical studies by @MH79 and @Metal82 found little difference in forecast accuracy between exponential smoothing and ARIMA models. This made the family of exponential smoothing procedures an attractive proposition [see @CKOS01].

The methods were less popular in academic circles until  @OKS97 introduced a state space formulation of some of the methods, which was extended in @HKSG02 to cover the full range of exponential smoothing methods.

## Handling Nonresponse
@DR87 defines three objectives that must be satisfied in an appropriate method for dealing with nonresponse as follows:
1 - adjusts estimates for the fact that on measured background variables the nonrespondents (or rate of non-response) differs from respondents
2 - expands standard errors to reflect any reduction in sample size
3 - exposes sensitivity of estimates and standard errors to possible differences between nonrespondents and respondents

By discarding nonrespondents, biased results will occur if non-responsiveness is correlated with values of variables @DR87.

Using an ad hoc prodecure using the mean, variance and correlation of responding units may seem sensible, but can still be biased. A negative-definite correlation matrix can result, causing negative variances in a regression @DR87.

### Multiple Imputation
@DR87 Impute m alternative values for the missing data, and run m separate models - one for each complete (imputed) data set.

Allows for us to treat the dataset as complete, and also flexibility in specification of imputed values.

For each posited model for nonresponse, two or more imputations are created (to reflect sample variability with known reason for nonresponsiveness). The m models reflect uncertainty about the reasons for nonresponse.

### Bayesian Methods to Adjust for Nonresponsiveness in aggregated figures
@YSL08 presents a Bayesian model for estimating classification probabilities and probabilities of respondentsâ€™ bias, in the context of self reported crime. With a comparative dataset which is deemed to be more reliable (in terms of responsiveness), empirical Bayes can be used to adjust the reported values to fit the other distribution*.


##Random Effects
@MS01 - chapter 7
Estimating Parameters in Balanced Data
- Uncorrelated subjects, uncorrelated between and within subjects, and correlated between but not within subjects can have their parameter estimated using analytical solutions. 
- Uncorrelated between and autocorrelated within subjects requiires a numerical solution to estimate parameters.

Estimating Paramters in Unbalanced Data
- Correlated between but not within subjects, cannot invert V = var(y) because of the unbalanced data, so cannot estimate parameters.
- Uncorrelatd subjects, uncorelated between and within subjects can have parameters estimated analytically.

@Faraway16 - chapter 10, 11, 12, 13
- Definitions of fixed and random effects. When in doubt of whether to use fixed or random effects, use random effects (references Gelman 2005).

Estimating Parameters
- Restricted maximum likelihood (REML) produces less biased estimated for variance than MLE for unbalanced data. Given that the number of levels for a factor (i.e. types in a class for which we are estimating with random effects) may not be large, but the bias for the MLE of the variance component will be large, we use REML. (pg 199)

Inference
- LR test to compare two nested models that differ only in their fixed effects will not work with REML, as REML considers linear combinations of data that remove the fixed effects. Instead, use MLE if an LR test is desired. 
- Chi-square test will tend to be conservative, so if you observe a significant effect using chi-square approximation, you can be confident that it is actually significant. Overall advise is to avoid using this approximation.
- Expected mean squares only works for simple models and balanced data.
- F-tests for fixed effects can be problematic when dealing with unbalanced data and complex models. P-values, test statistics and confidence intervals can be inaccurate due to the same problematic approximations.
- Parametric bootstrap works assuming normality for errors, and is a good candidate for unbalanced data.
- Bayesian methods also possible for fitting models.

Model Selection
- Akaike Information Criterion (AIC) can be confidently used when only fixed effects differ across models.
- Deviance Information Criteria (DIC) is popular for mixed models.
- Section A.3 for more on model selection.

Example
- Parametric Bootstrap to estimate LRT pg 204

Prediction
- Parametric bootstrap to get prediction intervals

Blocks (batches made in same period of time)
- Treat blocks as random effects

Nested Effects
- Remove random effects with lowest variance first, then test significance

Multilevel Models
- More reading